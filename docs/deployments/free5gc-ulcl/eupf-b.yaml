---

image:
  registry: ghcr.io
  repository: edgecomllc
  name: eupf
  tag: main
  pullPolicy: Always

deploymentStrategy:
  type: Recreate

command:
  - /bin/sh
  - -c
  - |
      set -x ; mkdir /etc/iproute2 ; echo "111 fromn3gtp" >> /etc/iproute2/rt_tables ; \
      ip rule add from 10.1.0.0/16 lookup fromn3gtp; \
      ip route add default via 10.100.100.1 dev n6 table fromn3gtp ;\
      sysctl -w net.ipv4.ip_forward=1  # to overcome the problem of switched off net.ipv4.ip_forward appearing in some environments ;\
      /app/bin/eupf $0 $@

args:
  - --config
  - /app/conf/config.yml

securityContext:
  privileged: true

podSecurityContext:
  sysctls:
  - name: net.ipv4.ip_forward
    value: "1"
  - name: net.ipv6.conf.all.forwarding
    value: "1"

configMaps:
  config:
    data:
      config.yml: |
        interface_name: [n3, n6]
        api_address: :8080
        pfcp_address: 10.100.50.241:8805
        metrics_address: :9090
        n3_address: 10.100.50.233

env:
  UPF_PFCP_NODE_ID: 10.100.50.241  # address on n4 interface
  # UPF_N3_ADDRESS: 10.100.50.233

volumes:
  - name: sys
    hostPath:
      path: /sys
  - name: config
    configMap:
      name: edgecomllc-eupf-config

volumeMounts:
  - name: sys
    mountPath: /sys
    readOnly:  true
  - name: config
    mountPath: /app/conf

metrics:
  enabled: true
  serviceMonitor:
    enabled: true
    additionalLabels:
      release: kube-prometheus-stack
    endpoints:
      port: metrics
      path: "/metrics"

extraContainerPorts:
  - name: pfcp
    containerPort: 8805
    protocol: UDP
  - name: metrics
    containerPort: 9090
    protocol: TCP

service:
  type: ClusterIP
  port: 8080
  extraPorts:
    - port: 8805
      targetPort: pfcp
      protocol: UDP
      name: pfcp
    - port: 9090
      targetPort: metrics
      protocol: TCP
      name: metrics

resources:
  limits:
    cpu: 100m
    memory: 128Mi
  requests:
    cpu: 100m
    memory: 128Mi

livenessProbe:
  tcpSocket:
    port: http
  initialDelaySeconds: 5
  periodSeconds: 10

readinessProbe:
  tcpSocket:
    port: http
  initialDelaySeconds: 5
  periodSeconds: 10

podAnnotations:
  k8s.v1.cni.cncf.io/networks: |
    [
      { "name": "n3network-upf",
        "interface": "n3",
        "ips": [ "10.100.50.233/28" ]
      },
      { "name": "n4network-upf",
        "interface": "n4",
        "ips": [ "10.100.50.241/29" ]
      },
      { "name": "n6ptp-upf",
        "interface": "n6",
        "ips": [ "10.100.100.12/24" ]
      }
    ]

extraDeploy:
  - apiVersion: k8s.cni.cncf.io/v1
    kind: NetworkAttachmentDefinition
    metadata:
      name: n3network-upf
    spec:
      config: |
        {
          "cniVersion": "0.3.1",
          "plugins": [
            {
              "type": "ipvlan",
              "capabilities": { "ips": true },
              "master": "ens3",
              "mode": "l2",
              "ipam": {
                "type": "static"
              }
            }
          ]
        }
  - apiVersion: k8s.cni.cncf.io/v1
    kind: NetworkAttachmentDefinition
    metadata:
      name: n4network-upf
    spec:
      config: |
        {
          "cniVersion": "0.3.1",
          "plugins": [
            {
              "type": "ipvlan",
              "capabilities": { "ips": true },
              "master": "ens3",
              "mode": "l2",
              "ipam": {
                "type": "static"
              }
            }
          ]
        }
  - apiVersion: k8s.cni.cncf.io/v1
    kind: NetworkAttachmentDefinition
    metadata:
      name: n6ptp-upf
    spec:
      config: |
        {
          "cniVersion": "0.3.1",
          "plugins": [
            {
              "type": "ptp",
              "capabilities": { "ips": true },
              "ipam": {
                "type": "host-local",
                "ranges": [
                    [
                        {
                            "subnet": "10.100.100.0/24",
                            "gateway": "10.100.100.1"
                        }
                    ]
                ],
                "routes": [
                  { "dst": "8.0.0.0/8" }
                ]
              }
            }
          ]
        }

  - apiVersion: batch/v1
    kind: Job
    metadata:
      name: rout4eupf
      # labels:
        # app: rout4eupf  # Deployment labels to match with replicaset labels and pods labels
    spec:
      # selector:
        # matchLabels:
          # app: rout4eupf # Replicaset to manage pods with labels
      template:
        # metadata:
          # labels:
            # app: rout4eupf  # Pods labels
        spec:
          hostNetwork: true
          restartPolicy: Never
          containers:
            - name: iprouteadd
              env:
              - name: UPF_POD_IP
                value: "10.100.100.12"  #addr at n6 in eupf pod
              - name: UPF_POOLS_CIDR
                value: "10.1.0.0/16"    # {{ .Values.global.uesubnet }} in towards5gs-helm
              image: alpine:3.17.3
              imagePullPolicy: IfNotPresent
              resources: {}
              securityContext:
                capabilities:
                  add:
                  - NET_ADMIN
                privileged: true
                runAsNonRoot: false
              command:
              - /bin/sh
              - -c
              - |
                  echo "start script"; set -x ;\
                  i=0; DEVNAME_PTP=""; \
                  while [ -z "$DEVNAME_PTP" ]; \
                  do \
                    echo "$i: wait 1 sec for DEVNAME_PTP"; sleep 1; \
                    DEVNAME_PTP=$(ip route list ${UPF_POD_IP} | awk '{print $3}'); \
                    i=$((i+1)); \
                  done ;\
                  ip route add ${UPF_POOLS_CIDR} via ${UPF_POD_IP} dev ${DEVNAME_PTP} onlink ;\
                  if [ $? = 0 ]; then \
                      echo "OK";  \
                  else \
                      echo "If ERR is File exists, possible it's OK, route already created.";  \
                  fi
